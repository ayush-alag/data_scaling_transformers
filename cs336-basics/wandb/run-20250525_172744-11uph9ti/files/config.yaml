_wandb:
    value:
        cli_version: 0.19.11
        m: []
        python_version: 3.13.3
        t:
            "1":
                - 1
                - 50
                - 55
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.13.3
            "5": 0.19.11
            "8":
                - 5
            "12": 0.19.11
            "13": linux-x86_64
model:
    value:
        context_length: 512
        d_ff: 2048
        d_model: 768
        num_heads: 12
        num_layers: 12
        rope_theta: 10000
        vocab_size: 50257
paths:
    value:
        model_output: output/your_data
        train_bin: /data/c-aalag/tokenized_cc2/full_data.bin
        valid_bin: /data/paloma/tokenized_paloma_c4_100_domains_validation.bin
training:
    value:
        adam_beta1: 0.9
        adam_beta2: 0.98
        adam_eps: 1e-09
        compile: true
        device: cuda
        dtype: bfloat16
        eval_batch_size: 128
        eval_interval: 2000
        eval_iterations: 1000
        gradient_accumulation_steps: 1
        log_interval: 20
        lr: 0.001
        max_grad_norm: 1
        save_checkpoints: true
        seed: 0
        train_batch_size: 128
        train_steps: 100000
        wandb_entity: ayushalag1
        wandb_project: cs336-data
        warmup_ratio: 0.01
        weight_decay: 0.1
